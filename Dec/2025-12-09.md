# 부하테스트 준비
    - 부하테스트(Load Test) : 시스템이 정상적으로 처리할 수 있는 최대 수준의 트래픽을 확인하는 테스트
    - 트래픽 : 시스템(서버, API, 웹서비스 등)에 들어오는 요청(request)의 흐름과 양
    - 스트레스 테스트(Stress Test) : 시스템이 의도적으로 감당할 수 있는 수준을 초과하는 트래픽을 넣어 망가질 때까지 테스트
    - 동시 사용자 수 (Concurrent Users, Concurrency) : 동시에 시스템을 사용하고 있는 사용자 수
    - RPS (Requests Per Second, 초당 요청 수) : 시스템이 1초 동안 처리하는 요청 개수
    - p95 응답 시간 (95th Percentile Latency) : 모든 요청 중 95%가 이 시간 이내에 응답되었다는 의미
    - 에러율 (Error Rate) : 전체 요청 중 실패한 요청의 비율

# 기술 스택
    - 프론트엔드 : React(화면을 동적으로 만들 수 있는 자바스크립트 라이브러리), Next.js(React를 더 편하게 쓰게 해주는 프레임워크)
    - 백엔드 : Node.js(자바스크립트로 서버를 만들 수 있게 해주는 환경), Express(Node.js 위에서 서버 기능을 쉽게 만들게 해주는 도구)
    - 실시간 : Socket.IO(실시간으로 화면을 즉시 업데이트)
    - Redis : 빠른 응답이 필요한 기능에 자주 사용, 보통 DB(MongoDB)는 하드디스크 기반 → 느림 / Redis는 메모리(RAM) 기반 → 매우 빠름
        - 캐시, 세션 저장, 실시간 기능(채팅방 목록, 온라인 유저 리스트 등), 큐/메시지 브로커(알림 보내기, 이미지 처리 등)

# Playwright, Artillery
    - Playwright : 웹사이트가 잘 동작하는지 자동으로 테스트하는 도구(프론트엔드 테스트)
    - Artillery : 서버가 높은 트래픽을 버티는지 테스트하는 도구(백엔드 테스트)

# E2E 시나리오(End-to-End Scenario) : 사용자가 서비스를 처음부터 끝까지 실제로 사용하는 흐름을 그대로 테스트하는 절차
    - 시나리오(E2E) 하나 = 가상의 사용자 1명 행동 패턴

# 캐시 : 자주 요청되는 데이터를 느린 곳(DB, 외부 API)에서 매번 가져오지 말고 빠른 곳(메모리, Redis)에 잠시 저장해두고 계속 쓰자!
    - 캐시 키 : 어떤 기준으로 저장할까? (예: user:{id}, room:{roomId}:lastMessages)
    - TTL (만료 시간): 얼마나 오래 캐시에 두고, 언제 삭제할까?
    - 캐시 히트율: 캐시에서 바로 찾은 비율
    - 캐시 후보 : 사용자 프로필, 프롬프트 템플릿, help 메시지 등
    -> 캐시 전략 설계

# HA 구성요소
    - 로드 밸런싱 : 요청을 여러 서버에 골고루 나눠줌
    - 데이터 복제 : 데이터를 여러 곳에 복사해서 한 곳이 고장 나도 문제 없게 함(Redis Sentinel: Redis가 죽으면 즉시 다른 Redis가 대신함)
    - 서비스 이중화 : 서비스를 여러 지역/서버에 두고, 하나가 고장 나도 다른 곳이 즉시 대신하도록 만드는 것
    - 자동화된 복구 : 문제가 생기면 서버가 자동으로 새로 만들어져서 복구되는 시스템
    - 모니터링 및 알림 (Monitoring & Alerting) : 서비스 상태를 실시간으로 감시하고, 문제가 생기면 즉시 알려주는 시스템

# 서버가 터지는 원인
    - DB가 너무 느려져서 전체 서비스가 막힘
        - 해결법
            - Redis 캐싱 : 자주 조회하는 데이터를 Redis에 저장
            - Redis Batch Load : 데이터를 한번에 묶어서 요청해서 DB를 덜 힘들게 함
            - 읽기 전용 repelica : 읽기 요청을 여러 DB로 분산해서 원본 DB가 부담을 덜 느낌
            - DB 쿼리 최적화(index) : DB가 데이터를 더 빨리 찾도록 도와주는 설정
    - 서버가 I/O나 CPU 작업때문에 바쁨(서버가 한 작업을 오래 붙잡고 있으면 다른 요청을 처리 못하고 밀림)
        - I/O = Input / Output = “데이터를 주고받는 과정” (서버가 외부와 데이터를 주고받는 모든 행동)
            - I/O 예시 : 데이터베이스에 값 읽어오기 (DB I/O), 파일 읽고 쓰기 (File I/O), 다른 서버(API) 호출 응답 기다리기 (Network I/O), 클라이언트에게 응답 보내기/받기
            - I/O = 데이터 읽기/쓰기 때문에 서버가 기다리는 시간
        - 해결법 
            - 로드밸런싱 + Auto Scaling : 서버 여러 대를 띄워서 요청을 나눠 받게 하는 방법
            - 메시지 큐(Kafka)로 비동기 처리 : 무거운 작업(이미지 처리, 알림 보내기 등)은 바로 실행하지 않고 일단 큐에 넣었다가 따로 처리 → 메인 서버는 빠르게 응답 가능
            - 비동기 I/O : 한 요청 처리 끝날 때까지 기다리는 게 아니라, 여러 요청을 동시에 처리할 수 있게 만드는 방식
    - 서버로 요청이 너무 많이 몰림(서버가 처리할 필요 없는 요청까지 몰리면 자원 낭비)
        - 해결법
            - CDN(S3, CloudFront) 사용, Reverse Proxy Cache (NGINX), 압축(gzip, brotli) 어려움

# Route53 
    - 사용자가 입력한 도메인 주소를 실제 서버(IP 주소)로 연결해줌
    - 역할 
    1. 도메인을 서버로 연결해줌 (DNS 서비스) (주소책 역할)
    2. 트래픽을 여러 서버로 분산할 수 있음 (로드밸런싱)
    3. 서버 장애 시 자동으로 다른 서버로 연결 (헬스체크 + Failover)

# CDN : 이미지, JS, CSS 같은 '파일'을 전 세계 여러 지역에 미리 복사해두고, 사용자에게 가장 가까운 곳에서 빠르게 보내주는 서비스
    - CloudFront(아마존), Cloudflare, Akamai

# 서버 경량화(Docker 컨테이너화)
    - 서버를 가볍고 이동 가능한 ‘박스’(컨테이너) 안에 넣어두는 것

# MSA 적용(Microservices)
    - 큰 서비스를 여러 개의 작은 서비스로 나누는 방식

# 메시지 큐(RabbitMQ, Kafka)
    - 서버가 바로 처리하지 않아도 되는 일들을 ‘큐’에 넣어두고 나중에 처리하는 시스템

# Fail over 
    - 서버가 고장나면, 준비해둔 다른 서버가 자동으로 대신 작동